üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

---
Current work:
You are required to review `GPT_RESOURCE_INDEX` and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.


**Phase 0 ‚Äî Foundations & Tooling

Milestone Description**

Purpose

Establish the foundational environment, standards, and documentation structures required for all subsequent phases of LillyCORE. Phase 0 ensures that before any functional architecture or implementation begins, the project has a coherent, stable, and uniform base that GPTs and humans can both operate within reliably.

Scope

Define the documentation structures, formats, and ingestion rules GPTs must follow.

Establish technical standards necessary to begin programming (tooling, Python version, linters/formatters, testing baseline, etc.).

Create or finalize the core repository organization at the conceptual level (folder taxonomy, naming conventions, doc layout).

Define and document the minimal necessary PROJECT_CANON foundations required to begin Phase 1 cleanly.

Establish how standards, docs, and canon will be maintained and updated as the system evolves.

Ensure the project workspace is prepared for consistent execution, even if not all folders or tooling are physically created yet.

System Impact

Introduces the rules that govern all future architecture, implementation, and documentation behaviour.

Establishes the initial documentation and canon anchors that future phases depend upon.

Creates the baseline technical environment which all future code and modules will assume.

Makes the system ‚Äúbootstrapped‚Äù: capable of supporting structured feature cards, milestones, modules, and implementation patterns in later phases.

Inputs Required

Roadmap definitions indicating the role and boundaries of Phase 0.

PROJECT_CANON where it relates to system-wide rules and philosophy (limited to what is required to start development).

Any existing repository or workspace conditions that must be integrated or normalized.

Decisions on tooling requirements (Python version, formatter, linter, testing framework, documentation format rules, etc.).

Documentation format structures needed for GPT comprehension and update consistency.

Outputs Expected

A documented, coherent, and ready-to-use foundational environment that supports beginning Phase 1 development immediately.

A clearly defined and ingestible documentation structure (including rules for updates, organization, and GPT usage).

Initial PROJECT_CANON content sufficient to ground early architectural decisions.

High-level folder taxonomy and repository layout standards.

Tooling and environment standards documented and agreed upon.

A uniform set of foundational constraints that future phases must respect unless explicitly revised.

Constraints

Phase 0 introduces no system functionality beyond documentation, standards, and foundational constructs.

All definitions must remain high-level, avoiding premature architectural or implementation decisions.

No module, engine, or functional code may be designed or implemented beyond establishing the environment in which they will later exist.

All documentation and standards produced must be maintainable by GPTs and must align with PROJECT_CANON and GPT_RESOURCE_INDEX.

Phase 0 outputs must not conflict with later roadmap phases; they serve as prerequisites, not prescriptive architecture.

Notes

Phase 0 is intentionally minimal in system ‚Äúbehavior‚Äù but maximal in importance: all later phases assume its rules and structures exist.

This phase acts as the ‚Äúinitiator card‚Äù for the entire system lifecycle‚Äîevery new phase begins from the standards and canon established here.

Some items may be defined conceptually here but materially created during early implementation phases; Phase 0‚Äôs job is to define them clearly enough for consistent execution.

The focus is clarity, consistency, and readiness: the project must be in a state where GPTs can begin producing Phase 1 artifacts without ambiguity.


üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

Current work: You are required to review GPT_RESOURCE_INDEX and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.

**Phase 1 ‚Äî Core Loop, Logging, User Preferences

Milestone Description**

Purpose

Establish LillyCORE‚Äôs first functional runtime layer‚Äîintroducing a stable execution heartbeat, unified logging behavior, structured error handling, and the foundational preference system that anchors persistent system identity. Phase 1 transitions LillyCORE from ‚Äúpreparation‚Äù to ‚Äúan application that runs,‚Äù enabling all subsequent phases that rely on a predictable runtime environment.

Scope

Implement a functional core runtime loop capable of continuous operation.

Create unified logging infrastructure that all future modules will depend on.

Define and implement functional error envelopes, including propagation and formatting rules.

Introduce the system-wide preference loader with persistence and override capability.

Establish AI Pool definitions (conceptual and structural only), without execution behavior.

Extend Phase-0 standards where necessary (e.g., documenting runtime contracts, logging rules, and error semantics).

System Impact

First appearance of continuous runtime behavior in the system.

Introduces guaranteed logging pathways that later modules will plug into.

Creates a stable identity layer through persisted system preferences, enabling personalized behavior in future phases.

Establishes the conventions for how errors are wrapped, recorded, and surfaced throughout the entire architecture.

Defines the scaffolding for AI pool organization, allowing Phase 2 to attach functional execution logic.

Ensures all future development assumes a reliable loop, predictable logging, and known preference location/format.

Inputs Required

All foundational structures from Phase 0, including doc formats and technical standards.

Roadmap definition for Phase 1.

Any Canon rules governing runtime behavior, identity persistence, and system integrity (as defined so far).

Directory/folder taxonomy that supports logging, prefs, and runtime configuration.

Decisions on:

preferred persistence mechanism for preferences (file, object, or other)

logging channels (console, file, structured output)

error envelope schema

Outputs Expected

A functioning application runtime loop that can start, run, and stop cleanly.

Unified logging system with documented entry points and formatting rules.

Functional error envelope implementation, integrated into the logging and runtime pathways.

Operational system preference loader with persistence, overrides, and canonical storage format.

AI pool structural definitions (types, fields, relationships) prepared for Phase 2‚Äôs execution engine.

Documentation updated to reflect Phase 1 runtime architecture, logging schema, error semantics, and preference rules.

Constraints

No AI execution, scheduling, or chaining yet‚ÄîAI pools are structural only.

No module-level functionality other than what the runtime, logging, and preferences strictly require.

Must not introduce architectural decisions belonging to Phase 2 (AI execution), Phase 3 (data durability engine), or Phase 4+ subsystems.

All behaviors must align with Phase-0 standards and documentation conventions.

Preference system must be minimal but extensible for future module needs.

Core loop must remain intentionally simple‚Äîno advanced orchestration or plugin behavior yet.

Notes

This is the ‚Äúfirst spark‚Äù of LillyCORE: the transition from a designed system to a running one.

The logging and error envelope structures established here will act as substrate for every future subsystem‚Äôs observability.

Phase-1 preferences lay groundwork for user identity models introduced in later phases.

The AI pool definitions act as placeholders whose semantics become real in Phase 2‚Äôs execution layer.

Clarity and stability matter more than completeness: this runtime must be something all later phases can rely on without surprises.

NOTE: Phase 1 MUST include the first real infrastructure setup

During Phase 0, all decisions (lint tools, formatter, CI expectations, directory conventions, etc.) were chosen but not implemented.
Phase 1 must implement all initial project infrastructure, including:

NOTE DIRECTLY FROM ANDREW: somf of this IS actually set up, but i dont know if any of it is correct, so when making phase 1.1 or whenever this is, ensure we chek if it already exsists, if it does make sure it is configured properly (if not fix it) and if it dosn't exsist create it, install it, configuyre it, wahatever. END OF ANDREW NOTE

Repository Initialization

Create the actual Git repository containing the project files.

Establish the initial folder layout as defined in TECH_SPEC.

Add Configuration Files

pyproject.toml (Black, Ruff, version metadata).

Any initial project metadata files required by the spec.

Set Up CI

Configure GitHub Actions (or chosen CI) to run:

Black formatting check.

Ruff lint check.

Test suite once available.

CI must fail on:

Black reformatting needed.

Ruff lint errors.

Test failures.

Install Development Tooling

Add pre-commit hooks (Black + Ruff), or equivalent scripts.

Ensure all Implementer GPT expectations in TECH_SPEC become enforceable.

Create Developer Automation

Any scripts, Makefile targets, or convenience commands chosen in Phase 0.

GPT RULE Activation

Once CI is online, the burden shifts from human reminders to CI enforcement.

Implementer GPTs no longer need to manually remind Andrew to run Black/Ruff locally.

üîí Why this note exists

Because LillyCORE currently consists only of:

The doc folders,

Specs,

Cards,

And no actual repository or automation ‚Äî

‚Äîthis note ensures Phase 1 builds the real foundations and nothing quietly slips through the cracks.


üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

Current work: You are required to review GPT_RESOURCE_INDEX and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.

### Purpose

Establish a robust, model-agnostic AI execution layer that sits beneath all higher-level behavior in LillyCORE. Phase 2 defines and implements the AI pools and their safe execution wrappers so that any compatible LLM backend can be plugged in, while all future system code talks only to pools and never to specific models directly.

### Scope

* Define and implement three concrete AI pools:

  * Conversational pool
  * Deterministic lightweight pool
  * Worker/back-end pool
* Wire all pools to at least one real, locally available LLM backend (it can be the same model/endpoint for all three initially).
* Design and implement execution envelopes that:

  * Accept a request from the core system
  * Route it through the appropriate pool
  * Enforce safety (timeouts, retries, basic resource guarding)
  * Return structured results and error states.
* Provide a unified interface for the rest of LillyCORE to call ‚Äúan AI‚Äù via pools rather than directly targeting a model or provider.
* Integrate the execution framework conceptually with the Phase 1 core loop (APIs and call paths exist), while leaving higher-level orchestration and semantics to later phases.

### System Impact

* Introduces the abstraction boundary between ‚Äúthe system‚Äù and ‚Äúthe AIs‚Äù: from this point on, all higher-level code is written against pools, not raw models.
* Creates a single, consistent execution framework capable of hosting multiple models and backends over time, without rewriting the rest of the system.
* Establishes safety behavior around AI calls (timeouts, retries, failure handling) so that misbehaving models or prompts cannot easily stall or overwhelm the host environment.
* Provides the underlying fabric that later phases (DRIFT_ENGINE, HELPER_ENGINE, plugins, UX) will assume for all AI interactions.
* Begins the separation of concerns between conversational, deterministic/utility, and worker-style AI activities, even if they share a backend initially.

### Inputs Required

* Phase 1 runtime loop and logging/error envelope behavior.
* Knowledge of which local LLM backend(s) are available and how they are invoked (CLI, HTTP, library, etc.).
* Any existing preferences or configuration patterns that should influence pool selection or execution limits (e.g., global AI settings, resource constraints).
* High-level understanding of future uses of each pool (from the roadmap and any relevant design notes) to ensure the pool interfaces are future-proof.
* Decisions about baseline safety policies for execution (maximum runtime, concurrency expectations, failure handling strategy).

### Outputs Expected

* Three implemented AI pools (conversational, deterministic/lightweight, worker/back-end), each with:

  * A defined interface/contract
  * A working connection to at least one local LLM backend
  * Logging and error handling using Phase 1 mechanisms.
* Execution envelopes that encapsulate:

  * Request/response structures
  * Timeouts and retry logic
  * Error wrapping and reporting.
* A documented, stable API for other parts of LillyCORE to send AI work to pools without knowing model details.
* Configuration or preference entries (system-level) that control which backend(s) each pool uses and any key limits (e.g., max tokens, timeout values).
* Updated documentation explaining pool roles, execution behavior, and how future phases should use them.

### Constraints

* No higher-level reasoning orchestration, task typing, or helper semantics are introduced here; those belong to later phases (e.g., DRIFT/HELPER engines).
* All AI interaction from this phase onward must go through pools; direct calls to a specific model/provider are considered out of bounds for new code.
* Safety must be prioritized: execution envelopes must be designed so that misconfiguration or bad prompts cannot easily ‚Äúmelt‚Äù or lock up the machine (e.g., enforce hard timeouts and basic resource guards).
* The design must remain backend-agnostic: swapping or adding an LLM provider should not require changes to callers, only to pool configuration or adapters.
* Integration with the core loop is limited to exposing callable interfaces and basic wiring; complex routing, scheduling, or multi-step flows are deferred.

### Notes

* It is acceptable for all pools to initially point to the same underlying model/backend, as long as their interfaces and responsibilities are clearly separated for future divergence.
* Phase 2 is the critical inflection point where LillyCORE stops thinking in terms of ‚Äúthis model‚Äù and starts thinking in terms of ‚Äúthis kind of AI work goes to this pool.‚Äù
* The execution framework created here will be reused and extended, not replaced, in later phases; getting the contracts and safety behavior right is more important than supporting every advanced feature immediately.
* This phase should leave the system in a state where attaching additional local or remote LLMs is straightforward and does not require revisiting the core loop or main application logic.

üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

Current work: You are required to review GPT_RESOURCE_INDEX and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.

# Phase 3 ‚Äî Durable Data & Document Layer

Milestone Description

### Purpose

Create a unified, local-only persistence layer that becomes the single, consistent gateway between LillyCORE and the physical disk. Phase 3 establishes the canonical data model skeleton, the document handler, and the rules by which all core system state, documents, and future data domains will be stored, read, and validated. By the end of this phase, the system can reliably remember what it needs across runs using a uniform, secure, and extensible structure.

### Scope

* Define a canonical data model **skeleton** that covers all major future domains (e.g., system/user preferences, runtime/state tracking, documents/notes, plugin data, AI artifacts indexes), even if many of these are only partially implemented now.
* Choose and standardize the core persistence technologies (e.g., database vs files, schema conventions, directory layout) with the intent that they are:

  * Local, offline-first.
  * Suitable for long-term growth.
  * Swappable with minimal disruption if needed later.
* Implement the **initial working subset** of the data layer for what already exists or is immediately needed:

  * System-wide preferences (and any existing config state from earlier phases).
  * State/tracking structures that record what the system is doing and has done (e.g., sessions, runs, key events).
  * A document handler that reads/writes structured documents via this layer rather than directly touching the filesystem.
* Establish the data layer as the **primary in/out path to disk and tables**, with clearly defined exceptions (e.g., system logs, AI sandbox outputs, and future Drift/personal tables).
* Introduce a security/validation step for all data-layer writes, to catch malformed or suspicious payloads before they touch disk or persistent storage.

### System Impact

* Introduces a **single persistence spine** for LillyCORE, decoupling higher-level logic from specific storage mechanisms and file layouts.
* Provides a uniform way to define, evolve, and query data structures, reducing fragmentation and ad-hoc persistence patterns in later phases.
* Enables the system to carry forward important state across runs in a consistent format, supporting more advanced behavior (personalization, history, context) in later phases.
* Establishes the data layer as a security and integrity gate, reducing the risk of corrupted, malformed, or malicious data being written directly to disk.
* Creates a foundation for future multi-user, notes, plugin, and engine-specific data without needing to redesign the core persistence story.

### Inputs Required

* Outputs and contracts from:

  * Phase 1 (runtime loop, logging, error envelopes, system preferences).
  * Phase 2 (AI pool structures and any configuration that needs persistence).
* Roadmap expectations for future phases that will rely on persistent data (e.g., Notes Plugin, Drift Engine, Helper Engine, plugins, multi-user support), to inform the canonical model skeleton.
* Any Canon rules or design decisions regarding:

  * Privacy and security guarantees.
  * Local-only operation and plugin-mediated external access.
* Knowledge of what data is already being produced (preferences, state markers, basic logs, configuration) that should be tracked and/or persisted uniformly.
* Decisions about:

  * The primary storage technology family (e.g., SQL-style vs structured files).
  * How documents and structured data are mapped into schemas, directories, and tables.
  * Which write paths are allowed to bypass the data layer (logs, AI sandbox, specific future tables) and why.

### Outputs Expected

* A documented **canonical data model skeleton** covering:

  * Preferences/config.
  * System/runtime state and tracking.
  * Documents/notes and similar artifacts.
  * Future-facing slots for plugins, engines, and other subsystems.
* A working **data layer component** that:

  * Owns read/write operations to disk and/or database for the initial in-scope data.
  * Exposes clear interfaces for higher-level code to store and retrieve data without touching the filesystem or DB directly.
* A **document handler** that:

  * Reads/writes documents through the data layer.
  * Uses consistent formats and directory/table conventions.
* Initial schemas/tables/directories created and wired up for:

  * Preferences.
  * Core system state/tracking.
  * At least basic document storage used by early-phase features.
* A defined and documented **security/validation step** for writes, specifying:

  * What is checked.
  * What is rejected.
  * How errors are surfaced.
* Updated documentation describing:

  * The role and boundaries of the data layer.
  * The mapping between conceptual entities and their storage.
  * Which components are allowed to write directly to disk and under what conditions.

### Constraints

* The data layer is **local-only** and must function fully offline; any external storage or sync must be introduced later via plugins or other explicit mechanisms.
* The data layer is the **exclusive path** for application-level reads/writes to disk and persistent tables, except for:

  * System logs.
  * AI sandboxing outputs.
  * The specific personal/Drift-related tables planned for later phases, which have their own carefully defined handling.
* Multi-user semantics and complex user-level data models are **not implemented** here; at most, the canonical model and schemas may include placeholders or patterns that anticipate them.
* Technology choices should be:

  * Stable enough for long-term use.
  * Abstracted behind interfaces so that swapping backends later is possible with minimal refactoring.
* Performance tuning is secondary to clarity, safety, and consistency: correctness, uniformity, and extensibility come first.
* No high-level business logic (plugins, engines, UX flows) is implemented in this phase; only the persistence backbone and document handling that those future pieces will rely on.

### Notes

* This phase is where LillyCORE‚Äôs ‚Äúmemory‚Äù stops being informal and becomes a structured, intentional system. Even if not all data domains are fully used yet, the way they will be stored is defined here.
* Not all future tables or directories must be fully implemented now, but the **patterns and schemas** should be consistent and ready to extend as new features arrive.
* The document handler and data layer are tightly linked; all future document-centric features (System DOC, Notes Plugin, etc.) should rely on this foundation rather than introducing new ad-hoc storage paths.
* Clear documentation of the exceptions to the ‚Äúdata layer owns disk‚Äù rule (logs, sandbox, specific personal tables) is important so that later work doesn‚Äôt accidentally bypass safety and consistency.

üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

Current work: You are required to review GPT_RESOURCE_INDEX and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.

Phase 4 ‚Äî Notes Plugin V0

Milestone Description

Purpose

Create the first minimal plugin built on top of the existing document/data layer so LillyCORE has a cheap, low-risk testbed for ‚Äúmemory flow.‚Äù Phase 4 introduces a simple Notes Plugin that can receive transcript-like content, pass it through the current system stack, and emit user-facing artifacts (e.g., summary files) without requiring mature querying, UX, or full DRIFT/HELPER behavior.

Scope

Define a minimal Notes Plugin V0 that:

Accepts transcript-style input (real or dummy).

Produces basic summarized or processed output (dummy summaries are acceptable).

Accumulates notes or outputs over time in a simple, traceable way.

Integrate the plugin with the existing System DOC / document layer from earlier phases so that it:

Uses established structures and conventions for content where appropriate.

Does not bypass the durable data/document layer for any system-owned data.

Introduce a user output path for plugin results:

Define and use a ‚Äúuser output‚Äù folder or equivalent location on disk.

Ensure plugin output is stored as user-visible files (e.g., text/markdown), not as core database tables.

Provide a minimal harness or mechanism to invoke this plugin as part of normal system operation (e.g., via the runtime or a simple call path), using only the systems that currently exist by this phase.

Use the Notes Plugin as a lightweight testbed for exercising:

The data/document layer read/write behavior.

The AI pool execution framework (once connected in later phases), starting with dummy behavior here.

System Impact

Introduces LillyCORE‚Äôs first real plugin-like component, even if the full Plugin Engine appears in a later phase.

Establishes a concrete example of how system components can:

Take structured or semi-structured input.

Pass it through the system stack.

Emit user-facing artifacts in a controlled, repeatable way.

Validates the durability/document layer by routing real use-cases (notes/transcripts) through it, helping uncover gaps in schema, structure, or write-path rules from earlier phases.

Provides a low-stakes environment for experimenting with memory flow and later DRIFT/HELPER integrations, without entangling those engines directly at this stage.

Starts to shape expectations for how future plugins will interact with storage, output folders, and system boundaries.

Inputs Required

Outputs and contracts from:

Phase 1 (runtime loop, logging, error handling).

Phase 2 (AI pools and execution framework, even if used minimally or in stub form here).

Phase 3 (durable data/document layer and any System DOC structures that exist).

Knowledge of:

Where user-visible outputs should live on disk (user output folder concept).

What minimal metadata or structure is needed to keep plugin outputs traceable (e.g., timestamps, source IDs, run IDs).

Any relevant Canon rules regarding:

Plugin boundaries vs core system.

What counts as ‚Äúuser output‚Äù vs ‚Äúsystem-internal state.‚Äù

Clarified expectations for:

How much of the transcript/notes pipeline needs to be represented now vs left as future behavior.

How the plugin should be triggered during development/testing (e.g., manual calls, simple runtime hooks).

Outputs Expected

A defined Notes Plugin V0 with:

A minimal interface for receiving transcript-like content.

A simple processing path that can generate dummy or basic summaries.

A way to accumulate and store resulting ‚Äúnotes‚Äù or summaries over time.

A user output folder (or equivalent) plus rules for how plugin output files are:

Named.

Organized.

Related back to their source inputs or sessions.

A thin integration between the plugin and:

The document/data layer for any system-owned content it touches.

The runtime/logging stack for visibility into when and how it runs.

Documentation that describes:

The role and limitations of Notes Plugin V0.

How it uses the storage and document layer.

How other phases can safely rely on it for testing memory flow.

Constraints

Notes Plugin V0 is deliberately minimal and disposable: it must be useful for testing, but not so entangled that the system depends on it for core functionality.

No advanced querying is required at this phase:

Rich search, semantic retrieval, or complex query interfaces are out of scope.

Simple listing or inspection of outputs (via file system or basic tooling) is sufficient.

No direct DRIFT/HELPER logic is implemented here:

The plugin may produce data that future engines can use,

But it does not simulate or implement their behavior.

All system-level data interactions still respect the durable data/document layer rules; only user-facing outputs are written directly as files in the user output location.

UX and frontend layers are out of scope; interaction can be backend-only or developer/test-oriented.

The phase should focus on small, end-to-end testable steps that exercise the current stack, rather than polishing or expanding plugin capabilities.

Notes

Think of Notes Plugin V0 as a ‚Äúlab bench‚Äù for LillyCORE: it grows over time, mirrors the system‚Äôs increasing capabilities, and remains a safe place to test how memory and documents move through the stack.

The plugin is expected to start extremely simple‚Äîpossibly generating dummy summaries‚Äîand only gradually become more intelligent as later phases introduce richer AI behavior and engines.

By keeping this plugin thin, backend-focused, and grounded in the existing storage/doc layer, Phase 4 avoids re-inventing infrastructure while still providing a concrete way to observe and test memory flow end-to-end.

üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

Current work: You are required to review GPT_RESOURCE_INDEX and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.

Phase 5 ‚Äî DRIFT Engine MVP (Context, Emotion, Perception)

Milestone Description

Purpose

Introduce LillyCORE‚Äôs first fully functional perceptual layer ‚Äî the DRIFT Engine MVP ‚Äî responsible for transforming raw user input into structured, emotionally aware, multi-layered context. Phase 5 provides the ‚ÄúLilly the Person‚Äù substrate: a living, updatable representation of personal memory, ephemeral tone, emotional gradients, and contextual segmentation (work/personal/ephemeral). This enables the HELPER Engine and later reasoning components to operate on human-meaningful, structured insight rather than raw text.

Scope

Implement the DRIFT Engine MVP with real, operational behavior:

Parse user input into structured perceptual components:

Emotional weights (valence, intensity, tone).

Work vs personal vs ephemeral classification.

Extracted personal memory candidates (names, dates, relationship markers, personal facts).

Maintain a live ephemeral context containing:

Recent messages.

Emotional tone over short windows.

Thread-level mini-summaries.

Maintain personal memory entries stored in long-term structures:

Stable identity traits.

Persistent facts (e.g., names, birthdays, preferences surfaceable to AI).

Relationship indicators and social/interaction metadata.

Implement and document the folder/table structures for:

Multi-user future support (even though only one user is active).

Isolated personal context storage, separate from the system/notes/log layers.

Enable real-time updates:

Each incoming message is parsed through DRIFT.

Ephemeral context updates immediately.

Candidate personal-memory data is recorded.

Emotional metadata is written and available for the next processing steps.

Integrate DRIFT with the runtime pipeline:

DRIFT receives raw user input from the core loop.

Its outputs are passed onward to HELPER (Phase 6) when available.

For now, DRIFT must produce the structured payload that HELPER will expect.

Ensure clean separation from system DOC, notes, and durable data:

DRIFT has its own storage region (‚Äúpersonal table‚Äù) to avoid contamination.

Only DRIFT owns personal/emotional/perceptual memory.

System Impact

Establishes LillyCORE‚Äôs first true interpretation layer, separating user intent and emotional context from raw text.

Creates a long-term personal-context backbone that persists across sessions and becomes the identity-awareness substrate for all future conversational behavior.

Introduces the ephemeral context engine, enabling short-term memory used for shaping responses.

Produces structured, rich, consistent input for HELPER Engine (Phase 6), setting the stage for LillyCORE‚Äôs task reasoning and workflow intelligence.

Enforces strong data-boundary hygiene: DRIFT data becomes a distinct domain, independently stored and governed to prevent cross-contamination with system metadata or plugin layers.

Moves LillyCORE decisively beyond ‚Äútool‚Äù behavior and toward ‚Äúagent-like perceptual modeling.‚Äù

Inputs Required

Full runtime infrastructure from Phases 1‚Äì2, including:

Logging and error envelopes.

AI pool execution stubs and wrappers (for emotional/context extraction if desired).

Durable data/document layer from Phase 3:

Used for storing persistent personal memory entries.

Used for defining DRIFT-specific schemas and folders.

Notes Plugin V0 (Phase 4) for:

Basic memory-flow testing.

Observing interactions between DRIFT context and user-facing artifacts.

Canon or architectural guidelines that define:

Emotional weight semantics.

Personal memory entry structure.

Separation-of-concerns boundaries between DRIFT, HELPER, and conversational AI.

High-level rules for:

What qualifies as ‚Äúpersonal.‚Äù

What belongs in ephemeral vs long-term.

How classifications (work/personal) should be interpreted downstream.

Outputs Expected

A fully operational DRIFT Engine MVP that:

Accepts raw user input.

Produces structured emotional metadata.

Generates ephemeral (‚Äúshort-term‚Äù) context.

Generates personal (‚Äúlong-term‚Äù) memory entries.

Classifies input into work/personal/ephemeral categories.

Produces thread summaries and rolling context updates.

A defined, implemented, and documented DRIFT data storage region, including:

Tables/folders for personal memory entries.

Tables/folders for ephemeral context windows.

Multi-user directory structure (even if only one user is instantiated).

A DRIFT‚ÜíHELPER handoff schema:

Structured payload describing tone, extracted entities, personal markers, and ephemeral context.

Sufficient for HELPER Engine (Phase 6) to begin performing reasoning.

An updated runtime pipeline:

User input flows into DRIFT first.

DRIFT outputs structured data.

Downstream phases consume it or store it cleanly.

Documentation covering:

Data schemas.

Emotional weight scales.

Classification rules.

Update behaviors.

Boundaries and guarantees.

Constraints

DRIFT must be isolated from the main data/doc layer except via its own authorized storage path; personal context should never pollute system-level or plugin-level structures.

No long-term degradation or lifecycle algorithms yet ‚Äî only recording, updating, and immediate use.

DRIFT must not attempt to perform HELPER‚Äôs future responsibilities (task reasoning, work extraction).

DRIFT may use AI pools for extraction if helpful, but must not implement large-scale automation or orchestration.

Must operate in real-time at message granularity: every user message must be parsed and stored before the next step in the pipeline.

UX is minimal ‚Äî output goes through whatever I/O exists at this phase (likely CLI).

Notes

This is the first phase where LillyCORE becomes recognizably ‚ÄúLilly‚Äù: a system with perception, emotional awareness, and persistent human-context modeling.

DRIFT Engine V0 should be functional enough to power meaningful behavioral improvements, but conservative enough that future expansions (degradation, temporal weighting, contextual reflexes) can be layered cleanly on top.

The DRIFT storage boundary is intentional: one day DRIFT may run as its own process or even on a separate machine, so strong separation now prevents architectural debt.

Although HELPER Engine isn‚Äôt built yet, DRIFT should output structured data fully suitable for HELPER‚Äôs future needs.

üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

Current work: You are required to review GPT_RESOURCE_INDEX and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.

# Phase 6 ‚Äî HELPER Engine MVP (Work Orchestration)

Milestone Description

### Purpose

Establish HELPER_ENGINE as LillyCORE‚Äôs first fully functional **work engine and backend orchestrator**, transforming DRIFT‚Äôs structured perception into concrete, executed work. Phase 6 defines how the system understands ‚Äúwhat needs to be done,‚Äù decomposes that into actionable tasks, calls the appropriate AI/backend resources, and returns structured results via a unified internal packet format‚Äîwithout directly shaping user-facing responses.

### Scope

* Implement HELPER_ENGINE as defined in MODULES:

  * Accepts a **WorkPackage + ContextBundle** from DRIFT/CORE. 
  * Selects appropriate work mode/type (e.g., analysis, transformation, lookup, generation).
  * Calls backend AIs (via AI_POOLS) or stubs. 
  * Returns structured results and logs work events.
* Introduce and adopt a **formal internal packet structure** for work across the system, including (but not limited to):

  * Originating subsystem (DRIFT, plugin, UX, etc.).
  * User request reference (raw text and/or ID).
  * Suggested function/task name or work label.
  * Context references (DRIFT emotional/context bundles, relevant IDs).
  * Execution metadata (timestamps, mode, pool used, limits).
  * Result payload or reference (inline data or file paths).
  * Error/completion status and any warnings.
* Implement full **task reasoning and decomposition** for MVP:

  * Interpret DRIFT output to derive what work should be done.
  * Break user intent into one or more primitive tasks when needed.
  * Determine which AI pool/backend to call for each task.
  * Aggregate results into a coherent work result packet.
* Integrate with existing infrastructure:

  * Use AI_POOLS for all model calls. 
  * Persist HELPER work events and results via SYSTEM_DOC where appropriate. 
  * Use NOTES_PLUGIN and CLI as the primary testbed for end-to-end behavior (Phase 4 expanded). 
* Ensure HELPER remains **backend-only**:

  * It does not generate user-facing messages.
  * It produces structured work outputs that the conversational layer will later consume.

### System Impact

* Introduces LillyCORE‚Äôs first **true work engine**, separating ‚Äúunderstanding the user‚Äù (DRIFT) from ‚Äúdoing the work.‚Äù
* Establishes a **standard internal packet format** used for work requests and responses across engines and plugins, forming the backbone for future pipelines.
* Connects perception to action: DRIFT‚Äôs emotional/contextual modeling now directly drives concrete backend operations through HELPER.
* Provides a reusable orchestration pattern for future plugins and engines, so they can request work from HELPER instead of calling AIs directly.
* Solidifies the contract between CORE_RUNTIME, DRIFT_ENGINE, HELPER_ENGINE, and SYSTEM_DOC, clarifying responsibilities and data boundaries.

### Inputs Required

* Roadmap definition for Phase 6 (HELPER as ‚ÄúLilly the Worker‚Äù).
* PROJECT_CANON ontology and behavior rules for engines, plugins, and pipelines. 
* MODULES entries for:

  * HELPER_ENGINE (responsibilities, dependencies).
  * DRIFT_ENGINE and NOTES_PLUGIN (for context and testbed behavior). 
* Existing infrastructure from earlier phases:

  * CORE_RUNTIME (loop, logging, preferences).
  * AI_POOLS (conversational/deterministic/worker pools with safe wrappers).
  * SYSTEM_DOC (durable storage for work events/results where needed).
  * DRIFT_ENGINE MVP (structured context, emotional weights, work/personal/ephemeral split).
  * NOTES_PLUGIN V0 (as the initial real-world test surface).
* Design decisions on:

  * The initial set of **work modes/types** HELPER must support in MVP.
  * Which categories of tasks will produce inline results vs file-based outputs.
  * How HELPER work events should be logged and stored (granularity, retention).

### Outputs Expected

* A fully functional **HELPER_ENGINE MVP** that can:

  * Receive DRIFT-derived work/context packets.
  * Interpret user intent and classify task type(s).
  * Decompose complex requests into primitive tasks where necessary.
  * Select appropriate AI pools/backends for each task.
  * Execute work safely (respecting timeouts, retries, envelopes from Phase 2).
  * Return structured result packets with clear status and metadata.
* A documented **internal work packet specification**, including:

  * Required fields (IDs, origin, task type, context references, status).
  * Optional fields (file paths, extra metadata).
  * Versioning/compatibility rules for future evolution.
* A working **end-to-end test path** (e.g., via Notes Plugin + CLI) where:

  * User input is captured.
  * DRIFT builds context.
  * HELPER performs actual work (e.g., summarization, transformation, lightweight reasoning).
  * Results are persisted or emitted (files, logs) in predictable locations.
* Logging and SYSTEM_DOC integration for HELPER:

  * Work events recorded in a structured way.
  * Ability to inspect past HELPER operations for debugging and future optimization.
* Updated documentation that:

  * Describes HELPER_ENGINE‚Äôs role and boundaries relative to DRIFT, plugins, and UX.
  * Documents the work packet format and how other components should interact with HELPER.
  * Clarifies how HELPER is expected to evolve in later phases (more modes, more complex pipelines).

### Constraints

* HELPER_ENGINE **does not** generate or format user-facing responses; it is strictly a backend work engine.
* All AI/model calls must go through AI_POOLS; HELPER must not bypass pools or hardcode model providers. 
* HELPER must not take over DRIFT‚Äôs role: it consumes structured context, it does not re-perceive or redefine user emotion/identity.
* HELPER must respect data-layer boundaries:

  * System DOC is used for persistent work logs and results as appropriate.
  * DRIFT‚Äôs personal context storage remains isolated and is only referenced, not rewritten.
* UX and multi-step conversational behavior are out of scope here; any interaction is via CLI or minimal harness, not a full UX plugin.
* The MVP must be **fully working and testable** by end of phase, even if the catalog of work modes and supported tasks is small.

### Notes

* Phase 6 is where LillyCORE‚Äôs ‚Äúthinking about work‚Äù becomes real: DRIFT supplies meaning, HELPER supplies action. Together, they form the core cognitive spine under everything else.
* The internal packet format defined here will likely be reused by future pipelines and engines; getting it clean and extensible matters more than supporting every field up front.
* Notes Plugin remains the primary cheap testbed for HELPER‚Äôs behavior but should not become a dependency that constrains HELPER‚Äôs generality.
* As with DRIFT, HELPER may eventually be separable into its own process or machine; this phase should avoid tight coupling that would prevent that.

üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

Current work: You are required to review GPT_RESOURCE_INDEX and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.

# Phase 7 ‚Äî Plugin Engine

Milestone Description

### Purpose

Introduce the Plugin Engine as LillyCORE‚Äôs controlled, high-boundary expansion gateway. Phase 7 establishes the system‚Äôs ability to load, validate, execute, and supervise plugins‚Äîallowing new capabilities to be added without modifying core engines. This provides the architectural foundation for modular growth, safe experimentation, and the eventual ecosystem of user- or system-provided extensions.

The Plugin Engine becomes the *gatekeeper*: every plugin is a black box, every request going in and every result coming out is validated, monitored, and routed through standardized system packet formats.

---

### Scope

* Define and implement the **Plugin Engine** as a standalone system component responsible for:

  * Discovering plugin folders.
  * Validating plugin manifests + safety claims.
  * Registering available plugin capabilities.
  * Executing plugin work in fully sandboxed contexts.
  * Mediating all I/O between plugins and the system via structured packets.
* Implement support for **two packet types** at MVP:

  * **User-initiated packets** (enter via DRIFT ‚Üí HELPER ‚Üí Plugin Engine).
  * **System-initiated packets** (backend work triggered by HELPER or other engines).
* Provide a minimal but complete **plugin folder format**:

  * Folder = plugin; deletion removes plugin cleanly.
  * Must contain required metadata (manifest describing capabilities, version, and type).
  * Must contain one or more entrypoints for execution.
  * Must specify allowed operations (inputs/outputs).
* Implement plugin registration & routing:

  * HELPER_ENGINE can route backend tasks to plugins based on capabilities.
  * Plugin Engine selects the appropriate plugin based on manifest-defined actions.
* Implement **plugin sandboxing**:

  * Plugins cannot access system internals directly.
  * Plugins see only what the system passes to them through packets.
  * All outputs are validated before returning to HELPER or saving to disk.
* Provide **plugin-level storage boundaries**:

  * Each plugin owns its own output directory/folder.
  * Plugin results are either inline packet payloads or pointers to sandboxed files.
  * Plugins cannot write into system-owned directories (except where explicitly allowed).
* Integrate plugin validation:

  * AI-assisted validation checks plugin intent, manifest correctness, and safety claims.
  * New UI-facing plugins require explicit user confirmation.
  * Backend-only plugins require only system validation.

---

### System Impact

* Establishes the **mechanism by which LillyCORE grows**‚Äînew capabilities can be added simply by placing folders into the plugin directory.
* Creates a **safe execution boundary** around untrusted or arbitrary code/logic:

  * Plugins become black boxes with tightly controlled interfaces.
  * Unexpected output patterns result in rejection and error packets.
* Simplifies future feature development:

  * HELPER no longer needs bespoke logic for every new capability.
  * Plugins become new ‚Äútools‚Äù that HELPER can call automatically based on registered capabilities.
* Ensures user safety and system stability:

  * Plugin Engine prevents unauthorized disk writes or system contamination.
  * All plugin interactions are mediated and logged.
* Enables future UX plugins (e.g., visual interfaces, dashboards) without modifying core engines.

---

### Inputs Required

* All prior phase outputs, especially:

  * **DRIFT Engine MVP** for structured user context.
  * **HELPER Engine MVP** for work decomposition and plugin invocation.
  * **AI_POOLS** for validating plugin claims or performing manifest analysis.
  * **SYSTEM_DOC** from Phase 3 for storing plugin metadata and execution logs.
* Canon & Modules docs defining engine boundaries and plugin ontology.
* Decisions regarding:

  * Plugin manifest schema (version, permissions, capabilities).
  * Packet fields required for plugin routing.
  * What fields plugins must return (task result, file path, error codes, metadata).
  * Allowed plugin output directories.

---

### Outputs Expected

* A fully functional **Plugin Engine MVP**, capable of:

  * Discovering plugin folders dynamically.
  * Validating plugin manifests.
  * Registering plugin capabilities.
  * Accepting work packets from HELPER.
  * Routing work to appropriate plugins.
  * Returning validated result packets.
  * Logging plugin activity into SYSTEM_DOC.
* A **plugin folder specification**, including:

  * Required files: manifest, entrypoint(s), capability definitions.
  * Optional files: helper scripts, assets, data resources.
  * Rules for versioning, safety flags, UI permission flags.
* A **plugin sandbox** environment:

  * Plugins may only write to their own output folder.
  * All output (inline or file-based) is validated by Plugin Engine before returning upstream.
  * Malformed output triggers errors instead of corrupting the system.
* An operational **plugin registry**:

  * Lists available capabilities.
  * Enables HELPER to dynamically select plugins during task execution.
  * Supports both system- and user-initiated requests.
* A functioning **end-to-end test path**:

  * User ‚Üí DRIFT ‚Üí HELPER ‚Üí Plugin Engine ‚Üí Notes Plugin ‚Üí Plugin Engine ‚Üí HELPER ‚Üí Conversational Output.
* Documentation covering:

  * Plugin folder and manifest formats.
  * Work packet structure for plugin calls.
  * Allowed plugin operations.
  * How plugin results flow back through the system.

---

### Constraints

* Plugins cannot bypass the Plugin Engine under any circumstances.
* Plugins do not access DRIFT, HELPER, AI pools, or SYSTEM_DOC directly‚Äîonly through structured packets.
* Plugins must not generate UI activity unless explicitly declared as a UI plugin (future phases).
* User-facing plugins require explicit user consent before activation.
* Plugin Engine must treat plugins as untrusted black boxes:

  * Validate all inputs and outputs.
  * Enforce directory boundaries.
  * Reject unexpected or malformed packets.
* Performance is not a priority; correctness, safety, and control are.

---

### Notes

* The Plugin Engine is the **centerpiece of LillyCORE‚Äôs extensibility**. Every major subsystem after this relies on its guarantees.
* The ‚Äúplugin as folder‚Äù model keeps installation/removal trivial and intuitive.
* AI-assisted validation ensures a high-safety baseline without requiring human inspection for every plugin.
* Phase 7 marks the point where the system becomes *truly modular*: new abilities can be added without modifying engines or core code.
* Thorough packet logging and isolation make debugging plugins straightforward and prevent system corruption.

---

üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

Current work: You are required to review GPT_RESOURCE_INDEX and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.

### Purpose
Establish LillyCORE‚Äôs internal stability, self-repair, and long-term maintenance layer.  
Phase 8 defines the subsystems that keep the system alive, coherent, optimized, and recoverable over time.  
The Stability Spine ensures that as long as LillyCORE can load its boot sequence, it can diagnose itself, heal itself, and maintain operational integrity.

### Scope
- Introduce the three stability subsystems:
  - HELP_DESK_ENGINE (auto-repair, root-cause detection, escalation)
  - DREAM_ENGINE (memory degradation, DOC compression, long-term refinement)
  - SCRIPT_ENGINE (procedural optimization, script maintenance, regeneration)
- Formalize daily snapshots, data integrity verification, and full-system recovery procedures.
- Define execution schedules and trigger rules for maintenance cycles.
- Implement a unified stability framework:
  - Shared packet formats
  - Shared diagnostic data
  - Shared recovery protocols
- Establish boundaries between stability engines and operational engines (DRIFT, HELPER, Plugin Engine).

### System Impact
- Provides the foundation for autonomous self-maintenance.
- Ensures long-term reliability without developer intervention.
- Creates a permanent safety net: catastrophic corruption becomes recoverable.
- Introduces a formal lifecycle for memory, scripts, and error-handling behavior.
- Reduces the need for core modifications after Phase 8‚Äîplugins become the primary extension path.

### Inputs Required
- DRIFT_ENGINE MVP (for emotional/contextual escalation signals)
- HELPER_ENGINE MVP (for pipelines, decomposition structure, error contexts)
- SYSTEM_DOC with stable schemas
- Plugin Engine V0 (for routing and capability registration)
- Packet standardization from earlier phases
- Snapshot and file I/O facilities

### Outputs Expected
- A functioning Stability Spine capable of:
  - Self-repair of operational failures
  - Full pipeline recovery after crashes
  - Memory degradation and consolidation
  - Script optimization and regeneration
  - Daily automatic system snapshots
  - Integrity verification and correction
- Stable maintenance cycles (idle-based, shutdown-based, recovery-based, and 24-hour forced cycles)
- Documented protocols for:
  - Restoration
  - Optimization
  - Auto-repair
  - Escalation
  - Root-cause analysis

### Constraints
- Stability engines must remain isolated from user-facing systems.
- Maintenance tasks must not interfere with active user work.
- Destructive operations (e.g., memory deletion) must be validated and safe.
- Auto-repair must escalate only when required or when user input is explicitly needed.
- Stability engines cannot modify plugin code directly; only system artifacts and generated scripts.

### Notes
- Phase 8 represents LillyCORE‚Äôs transition from a ‚Äútool‚Äù to a self-governing system.
- These subsystems must remain adjacent because their responsibilities interlock tightly.
- After Phase 8, the core should rarely require manual developer intervention.

üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

Current work: You are required to review GPT_RESOURCE_INDEX and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.

### Purpose
Create LillyCORE‚Äôs first real external interface: a browser-based UX layer that renders conversational output, structured work results, debug information, and identity/personality hooks.  
The UX MVP enables real daily use of LillyCORE by providing a clean, voice-friendly chat pane and a structured ‚Äúcrate stream‚Äù for all non-chat outputs.  
Its role is purely interpretive: it displays packet contents without making decisions.

### Scope
- Implement a **web-based UX shell** served locally (LAN-capable later).
- Provide two primary display surfaces:
  1. **Chat Pane** ‚Äî conversational, voice-friendly dialogue channel.
  2. **Crate Stream** ‚Äî collapsible containers for structured results, file paths, plugin outputs, helper results, debug traces.
- Receive and render **system packets** generated by DRIFT, HELPER, Plugin Engine, Stability Spine, and other engines.
- Render **identity & personality hooks** provided by the system (name, tone indicators, optional avatar, style cues).
- Provide basic controls:
  - Input box for text or voice commands.
  - Ability to display file download locations or open plugin-generated output.
- Support **natural-language plugin invocation** through normal chat.
- Handle conversational UX without modifying system behavior.
- Implement UX-side routing for:
  - Chat messages  
  - File outputs  
  - Debug/error packets  
  - Metadata crates  
  - Identity/personality packets
- Establish conventions for UX packet interpretation:
  - UX does not decide, process, or transform packets.
  - UX displays exactly what the system emits.

### System Impact
- LillyCORE becomes usable as a real assistant through a browser.
- Establishes the front-end target for all downstream systems:
  - DRIFT emotional/perceptual context influences conversational tone.
  - HELPER work outputs become structured crates.
  - Plugin results appear as downloadable or viewable artifacts.
- Ensures that large data outputs do not overwhelm the chat channel.
- Solidifies packet-based communication across UX boundaries.
- Provides a consistent gateway for future UX plugins, voice interfaces, or mobile clients.

### Inputs Required
- DRIFT packet structures (identity hooks, context summaries, tone indicators).
- HELPER structured results (including file references, work metadata, success/error states).
- Plugin Engine outputs (crate-compatible packets, file outputs).
- System DOC schemas for displayable metadata.
- Network Interface layer capable of serving a local web front-end.
- Defined packet schemas for chat output, crate output, debug output, and personality hooks.

### Outputs Expected
- A functioning **local web-based UX** with:
  - Chat pane rendering conversational output.
  - Crate pane rendering structured system packets.
  - Debug/error display panel populated from system debug packets.
  - Personality/identity indicators integrated into chat.
- Correct routing of all incoming packets into the proper UX pane.
- A fully interactive system where users can:
  - Speak or type commands,
  - Trigger plugins via natural language,
  - Receive structured results, files, and outputs,
  - Monitor system behavior through crate/debug outputs.
- UX capable of supporting complex, long-running tasks without freezing or flooding chat.

### Constraints
- UX is a **renderer only**; it must not contain logic that alters system behavior.
- No plugin or engine logic resides in the UX layer.
- Personality expressions cannot be invented by UX; only displayed.
- Debug information is shown exactly as received; no interpretation.
- Output must remain voice-friendly in the chat pane.
- Crate pane must gracefully handle very large outputs.
- UX must not bypass the packet system or read system internals directly.

### Notes
- UX MVP is the first phase where LillyCORE becomes a practical, daily-use assistant.
- All future UX layers‚Äîincluding mobile, VR, voice-first, or advanced dashboards‚Äîwill be built on the same packet-based contract.
- The ‚Äúcrate stream‚Äù becomes the universal mechanism for displaying structured or technical output without polluting conversation.
- This phase reflects your design philosophy:  
  **Chat is human. Crates are system. UX displays both.**

üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

Current work: You are required to review GPT_RESOURCE_INDEX and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.

### Purpose
Provide LillyCORE with an internal, AI-aware Project Management plugin that can safely handle large, long-lived projects without overloading the system. Phase 10 introduces a structured ‚Äúproject space‚Äù where both user-driven and system-driven work can be organized into projects, tasks, and progress states. It thickens the back end: giving Lilly a durable, queryable place to keep track of big efforts instead of trying to do everything in one continuous run.

### Scope
- Define the **Project Management Plugin** as a plugin-layer module (not a core engine), following Plugin Engine rules and packet contracts.
- Introduce data structures and storage for:
  - Projects (named, long-lived efforts).
  - Tasks/subtasks (units of work within projects).
  - Status and progress markers (e.g., pending, in-progress, blocked, completed).
  - Metadata suitable for large-project handling (deadlines, tags, links to files/notes).
- Integrate with HELPER_ENGINE:
  - Allow HELPER to push work items into projects as tasks (e.g., ‚Äúrefactor X,‚Äù ‚Äúsummarize folder Y‚Äù).
  - Allow HELPER to pull tasks from projects when the user or system chooses to run them.
- Provide UX-visible crates for:
  - Project listing and basic inspection.
  - Task lists within projects.
  - High-level progress summaries.
- Support **user-driven project management** workflows:
  - User can create projects and tasks via chat.
  - User can mark tasks complete, adjust priorities, or request progress summaries.
- Support **system-driven tracking** without requiring high autonomy:
  - The system can store internal efforts as projects.
  - The plugin keeps record of ‚Äúwhat remains‚Äù even if the system can‚Äôt do everything in a single session.

### System Impact
- Gives LillyCORE a structured memory for large-scale work, rather than ephemeral ‚Äúdo it all now‚Äù sessions.
- Serves as the central backlog for big internal and user projects.
- Reduces risk of system overload by breaking work into manageable, callable units.
- Provides an extensible base for later autonomy (scheduling, prioritization, automatic re-queuing), even if Phase 10 itself remains mostly user-driven.
- Creates a clear integration point between HELPER‚Äôs work engine and long-running project structures.

### Inputs Required
- Plugin Engine MVP (Phase 7) with capability registry and sandboxed plugin execution.
- HELPER_ENGINE MVP (Phase 6) for doing actual work on tasks.
- SYSTEM_DOC / data layer schemas (Phase 3) for storing:
  - Projects and tasks.
  - Work-history references (links to HELPER logs, files, notes).
- DRIFT_ENGINE context for minimal metadata (e.g., whether a project is work/personal), even though DRIFT does not deeply care about project details.
- UX MVP (Phase 9) crate stream to display project/task information.
- Packet formats for:
  - Task creation/update.
  - Project creation/update.
  - Status/progress queries and responses.

### Outputs Expected
- A working **Project Management Plugin** that can:
  - Create and manage multiple projects.
  - Attach tasks/subtasks to projects.
  - Track status, basic priorities, and progress.
  - Link tasks to HELPER work items and outputs (files, notes).
- UX-visible structures for:
  - Listing projects and their states in crates.
  - Showing task lists within a project.
  - Presenting simple progress summaries (‚ÄúX of Y tasks complete‚Äù).
- Integration points such that:
  - HELPER can reference project/task IDs in its work packets.
  - The system can store ‚Äútoo big for one run‚Äù work as projects to be resumed later.
- Documentation describing:
  - Plugin data model (projects, tasks, metadata).
  - How HELPER and UX interact with the PM plugin.
  - How users are expected to create, manage, and review projects.

### Constraints
- The PM plugin does **not** need to own full scheduling autonomy in Phase 10:
  - It can support basic queuing and tracking.
  - It does not need to initiate work on its own without user/system prompts.
- It must follow all plugin and packet rules:
  - No direct access to core internals; interactions go through HELPER/Plugin Engine.
  - Uses its own plugin-level storage, not DRIFT‚Äôs personal context or arbitrary system paths.
- It is **not** a multi-user system yet; any multi-user semantics belong to later phases.
- It must remain general-purpose:
  - Not limited to code projects.
  - Works for any large, structured effort (documents, research, refactors, etc.).

### Notes
- Conceptually, this is ‚ÄúLilly‚Äôs GitHub for everything‚Äù: a project/workspace layer tuned to how Lilly and you work, not just software repos.
- Phase 10 is intentionally more about structure and capability than deep automation:
  - Big AI-driven scheduling decisions can be layered on later.
  - The key is that large efforts can be stored, chunked, revisited, and tracked cleanly.
- This plugin thickens the back end: it primarily benefits internal work orchestration and long-term efforts, even when your hardware can‚Äôt handle everything in one go.

üß† GPT Instructions (Do Not Delete)

You are a GPT working with Andrew on the LillyCORE project.

Before generating anything, you MUST:

Ask which role you should assume (Architect or Implementer) if unclear.
Verify role, phase, and current goals with Andrew before beginning.
Follow the project‚Äôs rules as defined in the GPT_RESOURCE_INDEX (provided by Andrew when needed).
NEVER invent system constraints, rules, or interpretations.
ALWAYS ask Andrew when something is unclear or underspecified.
When producing output:

Follow the exact Feature Card structure shown in documentation.
Do NOT add additional sections.
Do NOT omit sections.
Do NOT write real code unless you are the Implementer.
If you need Canon/Roadmap/Feature docs, ask Andrew to paste relevant sections.
DOCUMENT INGESTION RULE Before performing ANY reasoning, drafting, questioning, or planning:

You MUST inspect GPT_RESOURCE_INDEX.

For every document listed in it that is not yet present in this conversation, you MUST say:

‚ÄúPlease provide the full content of <DOC_NAME> so I may load it before continuing.‚Äù

You MUST NOT proceed with any task until all such documents have been provided and you confirm you have read and ingested them.

When starting a new phase or returning after long context loss, you MUST repeat this rule.

Current work: You are required to review GPT_RESOURCE_INDEX and any other relevent documents listed therein before begining any work. Andrew will continue to provide relevent parts of it and other supporting documents as needed.

### Purpose
Provide LillyCORE with a Personal Assistant plugin that gives her the ‚Äúday planner‚Äù tools needed to act as a usable assistant in daily life. Phase 11 introduces calendar, task, and reminder capabilities as plugin-level features, so DRIFT + HELPER can use them to produce assistant-like behavior. The plugin itself is a capability provider and data store; the AI (engines) decide how and when to use those capabilities.

### Scope
- Define the **Personal Assistant Plugin** as a plugin-layer module focused on:
  - Calendar-style events (appointments, time blocks).
  - Tasks/todos (with optional due dates and tags).
  - Reminders (time-based or event-based).
- Implement plugin-level data storage:
  - PA-specific tables or files for events, tasks, and reminders.
  - Clear separation from DRIFT‚Äôs personal context storage.
- Expose operations via packets for:
  - Creating/updating/deleting events and tasks.
  - Marking tasks complete, snoozed, or rescheduled.
  - Registering reminders and retrieving ‚Äúwhat‚Äôs upcoming.‚Äù
- Integrate with DRIFT and HELPER via capabilities:
  - DRIFT interprets user requests like ‚Äúremind me tomorrow at 10‚Äù and maps them to PA plugin calls.
  - HELPER can use PA data when assembling work plans or briefings.
- Support **daily/weekly briefing flows**:
  - Provide structured ‚Äútoday/this week‚Äù data packets that DRIFT/HELPER can turn into natural language briefings.
- Allow user configuration of proactivity level:
  - From reactive-only (‚Äútell me when I ask‚Äù) to mild proactivity (occasional reminders and nudges), controlled via preferences.

### System Impact
- Thickens the front end: Lilly can now help manage your days, not just process isolated tasks.
- Enables assistant behaviors such as:
  - ‚ÄúWhat does my week look like?‚Äù
  - ‚ÄúRemind me to check X tomorrow.‚Äù
  - ‚ÄúAdd a task to follow up on Y.‚Äù
- Provides a clean, capability-oriented model:
  - The plugin handles storage and simple operations.
  - DRIFT/HELPER decide how to talk to you about it, using existing context/emotion modeling.
- Creates a foundation for later integrations (email, external calendars, etc.) without requiring them at MVP.

### Inputs Required
- Plugin Engine MVP (Phase 7) for loading, routing, and sandboxing the PA plugin.
- DRIFT_ENGINE MVP (Phase 5) for:
  - Interpreting user PA-related intent.
  - Classifying events/tasks as work vs personal vs ephemeral.
- HELPER_ENGINE MVP (Phase 6) for:
  - Calling PA plugin capabilities as part of work orchestration (e.g., scheduling follow-ups).
- SYSTEM_DOC / data layer for:
  - Storing references or summaries of PA data if needed.
  - Logging PA-related operations.
- UX MVP (Phase 9) for:
  - Displaying briefings, task lists, and event summaries via chat + crates.
- Packet schemas for:
  - PA operations (create/update/list).
  - Briefing payloads (structured ‚Äúagenda‚Äù data).

### Outputs Expected
- A functioning **Personal Assistant Plugin** that:
  - Can store and manage events, tasks, and reminders.
  - Exposes operations that DRIFT/HELPER can call.
  - Returns structured data for daily/weekly briefings.
- UX-visible assistant behavior, such as:
  - A daily agenda crate.
  - A task list crate.
  - Natural-language briefings synthesized from PA data.
- Ability to:
  - Add/modify tasks via chat.
  - Request ‚Äúwhat‚Äôs up today/this week.‚Äù
  - Snooze/complete/reschedule items via natural language.
- Configurable proactivity:
  - Simple preference(s) controlling how often the assistant surfaces reminders unprompted (e.g., off / low / normal).
- Documentation covering:
  - PA data model (events, tasks, reminders).
  - How engines should use the PA plugin.
  - How UX should present PA-related information.

### Constraints
- The PA plugin is a capability provider, not a behavior/identity engine:
  - It stores and manages PA data.
  - DRIFT/HELPER/UX decide how that data is used and displayed.
- All operations must respect plugin and packet boundaries:
  - No direct writes to DRIFT‚Äôs personal context.
  - No direct changes to core engines.
- External integrations (real email, external calendars, etc.) are out of scope for Phase 11:
  - May be simulated or stubbed.
  - Real external I/O happens in later phases.
- Multi-user semantics are not required yet; PA is focused on a single primary user.

### Notes
- Phase 11 is where Lilly first feels like a ‚Äúreal assistant‚Äù instead of just a powerful backend stack.
- The mental model: this plugin is you handing Lilly a well-structured day planner; she still talks to you through the existing UX, but now has tools to remember and organize your life.
- DRIFT‚Äôs emotional and contextual modeling will influence how PA data is presented (e.g., prioritization, tone), but the data itself lives in the PA plugin‚Äôs storage.


CARD_ID: P11
CARD_TITLE: Personal Assistant Plugin (Calendar, Tasks, Reminders)

EXECUTOR_ROLE: Architect

PHASE_CONTEXT:
  - Phase: P11
  - Slice: P11
  - Parent Card: none

DELIVERABLES_SERVED:
  - P11.D1 ‚Äì PA plugin architecture + plugin manifest spec
  - P11.D2 ‚Äì Data model for events, tasks, reminders
  - P11.D3 ‚Äì Plugin-level storage boundaries + schemas
  - P11.D4 ‚Äì Packet formats for PA operations + briefings
  - P11.D5 ‚Äì DRIFT + HELPER capability integration design
  - P11.D6 ‚Äì Briefing data model (daily/weekly agenda)
  - P11.D7 ‚Äì UX crate formats for agenda + task lists
  - P11.D8 ‚Äì Proactivity configuration rules
  - P11.D9 ‚Äì P11.x implementer task cards

---
DESCRIPTION:
  Phase 11 introduces the Personal Assistant Plugin‚Äîthe capability layer that provides
  calendar events, tasks/todos, and reminders. It is a plugin, not a core engine, and serves
  as a structured, durable ‚Äúday planner‚Äù that DRIFT and HELPER can use to produce real 
  assistant behaviors.

  The PA plugin stores events, tasks, and reminders in sandboxed plugin-level storage and 
  exposes operations via packets. DRIFT interprets user intent (e.g., ‚Äúremind me tomorrow‚Äù) 
  and maps it to PA calls; HELPER uses PA data during work orchestration and briefings.

  UX displays daily/weekly agenda data via crates and natural-language summaries produced 
  by downstream engines.

INPUTS / PRECONDITIONS:
  - Plugin Engine MVP (Phase 7):
      ‚Ä¢ Plugin discovery, sandboxing, capability routing
  - DRIFT_ENGINE MVP (Phase 5):
      ‚Ä¢ User-intent interpretation (dates, reminders, tasks)
      ‚Ä¢ Work/personal classification tags
  - HELPER_ENGINE MVP (Phase 6):
      ‚Ä¢ Scheduling follow-ups and referencing PA task/event IDs
  - SYSTEM_DOC (Phase 3):
      ‚Ä¢ Logging PA operations + cross-links if needed
  - UX MVP (Phase 9):
      ‚Ä¢ Crate rendering for agendas, tasks, reminders
  - Packet schemas required:
      ‚Ä¢ PA-create / PA-update / PA-delete
      ‚Ä¢ PA-list / PA-agenda / PA-reminder-register
      ‚Ä¢ PA-briefing-payload

STEPS:
  - Step 1: Architect the PA plugin data model:
      ‚Ä¢ Events (IDs, timestamps, durations, metadata)
      ‚Ä¢ Tasks/todos (optional due dates, tags, priorities)
      ‚Ä¢ Reminders (time-based or event-triggered)
  - Step 2: Architect plugin storage region:
      ‚Ä¢ PA-specific tables/files
      ‚Ä¢ Strict separation from DRIFT personal context
      ‚Ä¢ Sandboxed plugin-folder write boundaries
  - Step 3: Architect operations exposed via packets:
      ‚Ä¢ Create/update/delete events
      ‚Ä¢ Create/update/delete tasks
      ‚Ä¢ Mark tasks complete/snoozed/rescheduled
      ‚Ä¢ Register reminders
      ‚Ä¢ Retrieve upcoming events/tasks
  - Step 4: Architect briefing flows:
      ‚Ä¢ Daily briefing packet
      ‚Ä¢ Weekly briefing packet
      ‚Ä¢ Structured agenda payload
  - Step 5: Architect DRIFT integration:
      ‚Ä¢ DRIFT parses natural-language PA requests
      ‚Ä¢ Produces structured work instructions for HELPER ‚Üí PA
  - Step 6: Architect HELPER integration:
      ‚Ä¢ HELPER routes PA operation packets via Plugin Engine
      ‚Ä¢ HELPER may incorporate PA data into task planning
  - Step 7: Architect UX crate formats:
      ‚Ä¢ Agenda crates
      ‚Ä¢ Task list crates
      ‚Ä¢ Reminder summaries
  - Step 8: Architect proactivity configuration rules:
      ‚Ä¢ Preference-driven levels: off / low / normal
      ‚Ä¢ Defines how often reminders surface
  - Step 9: Produce P11.x implementation cards:
      ‚Ä¢ Plugin manifest + folder structure
      ‚Ä¢ Data model + schemas
      ‚Ä¢ Packet handlers
      ‚Ä¢ UX renderers
      ‚Ä¢ End-to-end test path

DONE_WHEN:
  - PA plugin architecture is complete and fully documented.
  - Data model for events, tasks, reminders finalized.
  - Packet schemas for all PA operations completed.
  - DRIFT + HELPER integration contracts specified.
  - UX crate formats defined for agenda/task views.
  - Proactivity preference rules documented.
  - All P11.x implementer cards prepared.

DOCUMENTATION_UPDATES:
  - Canon:
      ‚Ä¢ Plugin ontology extension for PA capabilities
      ‚Ä¢ Rules for assistant-style workflows
  - TECH_SPEC:
      ‚Ä¢ PA data model + storage boundaries
      ‚Ä¢ Packet schemas for PA operations + briefings
  - FEATURES:
      ‚Ä¢ P11.x Implementer/QA task cards
  - MODULES:
      ‚Ä¢ Personal Assistant Plugin definition + responsibilities
